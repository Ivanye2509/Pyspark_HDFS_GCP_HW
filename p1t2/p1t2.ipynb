{"cells":[{"cell_type":"code","execution_count":1,"id":"fa30d6ac","metadata":{},"outputs":[],"source":["import os\n","os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.12:0.14.0 pyspark-shell'"]},{"cell_type":"code","execution_count":2,"id":"c6b73dd8","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[":: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"]},{"name":"stderr","output_type":"stream","text":["Ivy Default Cache set to: /root/.ivy2/cache\n","The jars for the packages stored in: /root/.ivy2/jars\n","com.databricks#spark-xml_2.12 added as a dependency\n",":: resolving dependencies :: org.apache.spark#spark-submit-parent-7568939b-68d7-44e7-a869-9d647c8dcb8e;1.0\n","\tconfs: [default]\n","\tfound com.databricks#spark-xml_2.12;0.14.0 in central\n","\tfound commons-io#commons-io;2.8.0 in central\n","\tfound org.glassfish.jaxb#txw2;2.3.4 in central\n","\tfound org.apache.ws.xmlschema#xmlschema-core;2.2.5 in central\n",":: resolution report :: resolve 305ms :: artifacts dl 8ms\n","\t:: modules in use:\n","\tcom.databricks#spark-xml_2.12;0.14.0 from central in [default]\n","\tcommons-io#commons-io;2.8.0 from central in [default]\n","\torg.apache.ws.xmlschema#xmlschema-core;2.2.5 from central in [default]\n","\torg.glassfish.jaxb#txw2;2.3.4 from central in [default]\n","\t---------------------------------------------------------------------\n","\t|                  |            modules            ||   artifacts   |\n","\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n","\t---------------------------------------------------------------------\n","\t|      default     |   4   |   0   |   0   |   0   ||   4   |   0   |\n","\t---------------------------------------------------------------------\n",":: retrieving :: org.apache.spark#spark-submit-parent-7568939b-68d7-44e7-a869-9d647c8dcb8e\n","\tconfs: [default]\n","\t0 artifacts copied, 4 already retrieved (0kB/9ms)\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","22/05/01 04:31:02 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n","22/05/01 04:31:02 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n","22/05/01 04:31:02 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n","22/05/01 04:31:02 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n","22/05/01 04:31:05 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/com.databricks_spark-xml_2.12-0.14.0.jar added multiple times to distributed cache.\n","22/05/01 04:31:05 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/commons-io_commons-io-2.8.0.jar added multiple times to distributed cache.\n","22/05/01 04:31:05 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/org.glassfish.jaxb_txw2-2.3.4.jar added multiple times to distributed cache.\n","22/05/01 04:31:05 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar added multiple times to distributed cache.\n","                                                                                \r"]}],"source":["from pyspark.sql import SparkSession\n","spark = SparkSession.builder.getOrCreate()\n","df = spark.read.format('xml').options(rowTag='page').load('hdfs:/enwiki_small.xml')"]},{"cell_type":"code","execution_count":3,"id":"061ab89a","metadata":{"scrolled":false},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["import regex\n","from pyspark.sql.types import StringType,ArrayType\n","from pyspark.sql.functions import udf, col,explode\n","\n","\n","def clean_title(titles):\n","    #All the letters should be convert to lower case.\n","    return titles.lower()\n","\n","def parse(match_):\n","    ret = None\n","    match_ = match_.split(\"|\")\n","    for ele in match_:\n","        if \"#\" in ele:\n","            continue\n","        elif (\":\" in ele) and (not ele.startswith(\"Category:\")):\n","            continue\n","        else:\n","            ret = ele\n","            break\n","            \n","    if ret:\n","        return ret.lower()\n","    else:\n","        return ret\n","\n","def clean_text(revisions):\n","    #All the letters should be convert to lower case.\n","    text = revisions[\"text\"]['_VALUE']\n","    links_ = []\n","    #If multiple links appear in the brackets, take the first one.(Ignore links that contain a #)\n","    matches = regex.findall(r'\\[\\[((?:[^[\\]]+|(?R))*+)\\]\\]', text)\n","    for match in matches:\n","            link = parse(match)\n","            if link:\n","                links_.append(link)\n","    if len(links_) > 0:\n","        return links_\n","    else:\n","        return None\n","    \n","           \n","clean_title_udf = udf(lambda k: clean_title(k), StringType())\n","clean_text_udf = udf(lambda k: clean_text(k), ArrayType(StringType()))\n","\n","\n","output = df.withColumn(\"title\",clean_title_udf(col(\"title\"))).\\\n","withColumn(\"links\", clean_text_udf(col(\"revision\"))).\\\n","select(\"title\",explode(\"links\")).withColumnRenamed(\"col\",\"links\")\n","\n","output.filter(output.links.isNotNull()).repartition(1).orderBy([\"title\",\"links\"]).limit(5).\\\n","write.csv(\"gs://csee4121homework/outputs/p1t2.csv\",mode=\"overwrite\",sep = \"\\t\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":5}